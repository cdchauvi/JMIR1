{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "# Choix du label \n",
    "\n",
    "#label = 'Label_2'\n",
    "#nombre_labels = 5\n",
    "\n",
    "label = 'Label_1'\n",
    "nombre_labels = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing standard libraries for every machine/deep learning pipeline\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Importing specific libraries for data prerpcessing, model archtecture choice, training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x270a9413190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# 5. Pytorch random number generator\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "epochs = 20\n",
    "MAX_LEN = 128\n",
    "batch_size = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df_training = pd.read_csv('Projet_Tweet_vaccin_fichier_1.1_labelises_pour_creer_la_fonction.csv', delimiter = \";\", encoding = 'latin_1')\n",
    "df_validation = pd.read_csv('Projet_Tweet_vaccin_fichier_1.2_labelises_pour_tester_la_fonction.csv', delimiter = \";\", encoding = 'latin_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_training, df_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CamemBERT tokenizer\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert/camembert-large',do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "# Creates list of texts and labels\n",
    "text = df['text'].to_list()\n",
    "labels = df[label].to_list()\n",
    "\n",
    "#user tokenizer to convert tokenizer = CamembertTokenizer.from_pretrained('camembert-base',do_lower_case=True)ces into tokenizer\n",
    "input_ids  = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN) for sent in text]\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]  \n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(input_ids, labels, attention_masks,\n",
    "                                                            random_state=42, test_size=0.1)\n",
    "\n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert/camembert-large were not used when initializing CamembertForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert/camembert-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CamembertForSequenceClassification, the pretrained camembert model with a single linear classification layer on top. \n",
    "model = CamembertForSequenceClassification.from_pretrained('camembert/camembert-large', num_labels = nombre_labels)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cdcha\\Anaconda3\\envs\\transformers8\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=10e-8)\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.337529186849241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   5%|▌         | 1/20 [20:02<6:20:39, 1202.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.34927536231884054\n",
      "Train loss: 1.3111118872960408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 2/20 [40:04<6:00:44, 1202.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3498550724637681\n",
      "Train loss: 1.2710235913594563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  15%|█▌        | 3/20 [1:00:10<5:41:09, 1204.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4515942028985507\n",
      "Train loss: 1.1205914285447862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 4/20 [1:20:13<5:20:55, 1203.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.40492753623188404\n",
      "Train loss: 1.0083588163057964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|██▌       | 5/20 [1:40:16<5:00:48, 1203.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4721739130434783\n",
      "Train loss: 0.799042484274617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|███       | 6/20 [2:00:15<4:40:26, 1201.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.513913043478261\n",
      "Train loss: 0.607875923315684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  35%|███▌      | 7/20 [2:20:17<4:20:23, 1201.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5423188405797101\n",
      "Train loss: 0.4106846291709829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 8/20 [2:40:20<4:00:27, 1202.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5217391304347826\n",
      "Train loss: 0.23684850997394985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  45%|████▌     | 9/20 [3:00:21<3:40:22, 1202.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5084057971014492\n",
      "Train loss: 0.17725993030601078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 10/20 [3:20:24<3:20:23, 1202.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5078260869565218\n",
      "Train loss: 0.09808638215892845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  55%|█████▌    | 11/20 [3:40:26<3:00:20, 1202.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.52\n",
      "Train loss: 0.05924447260245129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 12/20 [4:00:29<2:40:19, 1202.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5205797101449275\n",
      "Train loss: 0.029423664461959292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  65%|██████▌   | 13/20 [4:20:32<2:20:18, 1202.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5211594202898551\n",
      "Train loss: 0.027297678748490633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|███████   | 14/20 [4:40:32<2:00:10, 1201.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5344927536231884\n",
      "Train loss: 0.03154577407985926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  75%|███████▌  | 15/20 [5:00:32<1:40:05, 1201.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5489855072463768\n",
      "Train loss: 0.02258285853356399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 16/20 [5:20:32<1:20:03, 1200.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5362318840579711\n",
      "Train loss: 0.015384414112540308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  85%|████████▌ | 17/20 [5:40:34<1:00:03, 1201.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5356521739130434\n",
      "Train loss: 0.008251210243475658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|█████████ | 18/20 [6:00:37<40:03, 1201.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5417391304347826\n",
      "Train loss: 0.006305695330310199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  95%|█████████▌| 19/20 [6:20:40<20:02, 1202.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5284057971014492\n",
      "Train loss: 0.006153288918236892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [6:40:43<00:00, 1202.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5356521739130434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting if we want to visualize training evolution per epochs after the training process\n",
    "train_loss_set = []\n",
    "loss_train = []\n",
    "accuracy_validation = []\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):  \n",
    "    # Tracking variables for training\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Get loss value\n",
    "        loss = outputs[0]\n",
    "        # Add it to train loss list\n",
    "        train_loss_set.append(loss.item())    \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "    loss_train.append(tr_loss/nb_tr_steps)\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "    # Tracking variables for validation\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Validation of the model\n",
    "    model.eval()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions\n",
    "            outputs =  model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss, logits = outputs[:2]\n",
    "    \n",
    "        # Move logits and labels to CPU if GPU is used\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "    \n",
    "    accuracy_validation.append(eval_accuracy/nb_eval_steps)\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_train, label = 'Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('Training_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_validation, label = 'Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('Validation_accuracy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_to_proba(x):\n",
    "\n",
    "    x = 1/(1+np.exp(-logits))\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i,:] = x[i,:]/np.sum(x[i,:])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.read_csv('Projet_Tweet_vaccin_fichier_3_pour_tester_la_fonction.csv', delimiter = \";\", \n",
    "                             encoding = 'latin_1')['text'].to_list()\n",
    "comments = tt[0:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the comments\n",
    "tokenized_comments_ids = [tokenizer.encode(comment,add_special_tokens=True,max_length=MAX_LEN) for comment in comments]\n",
    "# Pad the resulted encoded comments\n",
    "tokenized_comments_ids = pad_sequences(tokenized_comments_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks \n",
    "attention_masks = []\n",
    "for seq in tokenized_comments_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)\n",
    "\n",
    "prediction_inputs = torch.tensor(tokenized_comments_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the finetuned model (Camembert)\n",
    "flat_pred = []\n",
    "with torch.no_grad():\n",
    "    # Forward pass, calculate logit predictions\n",
    "    outputs =  model(prediction_inputs.to(device),token_type_ids=None, attention_mask=prediction_masks.to(device))\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy() \n",
    "    flat_pred.extend(np.argmax(logits, axis=1).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"tweet\": comments, \"classification\": flat_pred})\n",
    "df.to_csv(\"classification_label1.csv\",index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
