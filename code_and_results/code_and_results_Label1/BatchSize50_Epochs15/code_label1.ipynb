{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "# Choix du label \n",
    "\n",
    "#label = 'Label_2'\n",
    "#nombre_labels = 5\n",
    "\n",
    "label = 'Label_1'\n",
    "nombre_labels = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing standard libraries for every machine/deep learning pipeline\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Importing specific libraries for data prerpcessing, model archtecture choice, training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1fc17a43190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# 5. Pytorch random number generator\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "epochs = 15\n",
    "MAX_LEN = 128\n",
    "batch_size = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df_training = pd.read_csv('Projet_Tweet_vaccin_fichier_1.1_labelises_pour_creer_la_fonction.csv', delimiter = \";\", encoding = 'latin_1')\n",
    "df_validation = pd.read_csv('Projet_Tweet_vaccin_fichier_1.2_labelises_pour_tester_la_fonction.csv', delimiter = \";\", encoding = 'latin_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_training, df_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CamemBERT tokenizer\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert/camembert-large',do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "# Creates list of texts and labels\n",
    "text = df['text'].to_list()\n",
    "labels = df[label].to_list()\n",
    "\n",
    "#user tokenizer to convert tokenizer = CamembertTokenizer.from_pretrained('camembert-base',do_lower_case=True)ces into tokenizer\n",
    "input_ids  = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN) for sent in text]\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]  \n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(input_ids, labels, attention_masks,\n",
    "                                                            random_state=42, test_size=0.1)\n",
    "\n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert/camembert-large were not used when initializing CamembertForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert/camembert-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CamembertForSequenceClassification, the pretrained camembert model with a single linear classification layer on top. \n",
    "model = CamembertForSequenceClassification.from_pretrained('camembert/camembert-large', num_labels = nombre_labels)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cdcha\\Anaconda3\\envs\\transformers8\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=10e-8)\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.337529186849241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|▋         | 1/15 [19:45<4:36:35, 1185.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.34927536231884054\n",
      "Train loss: 1.3111118872960408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|█▎        | 2/15 [39:31<4:16:55, 1185.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3498550724637681\n",
      "Train loss: 1.2710235913594563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 3/15 [59:15<3:56:59, 1184.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4515942028985507\n",
      "Train loss: 1.1205914285447862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|██▋       | 4/15 [1:18:57<3:37:00, 1183.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.40492753623188404\n",
      "Train loss: 1.0083588163057964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|███▎      | 5/15 [1:38:39<3:17:12, 1183.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4721739130434783\n",
      "Train loss: 0.799042484274617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 6/15 [1:58:22<2:57:28, 1183.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.513913043478261\n",
      "Train loss: 0.607875923315684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|████▋     | 7/15 [2:18:05<2:37:45, 1183.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5423188405797101\n",
      "Train loss: 0.4106846291709829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|█████▎    | 8/15 [2:37:50<2:18:05, 1183.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5217391304347826\n",
      "Train loss: 0.23684850997394985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 9/15 [2:57:35<1:58:23, 1183.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5084057971014492\n",
      "Train loss: 0.17725993030601078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████▋   | 10/15 [3:17:20<1:38:41, 1184.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5078260869565218\n",
      "Train loss: 0.09808638215892845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|███████▎  | 11/15 [3:37:06<1:18:59, 1184.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.52\n",
      "Train loss: 0.05924447260245129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 12/15 [3:56:49<59:13, 1184.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5205797101449275\n",
      "Train loss: 0.029423664461959292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|████████▋ | 13/15 [4:16:51<39:39, 1189.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5211594202898551\n",
      "Train loss: 0.027297678748490633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|█████████▎| 14/15 [4:37:06<19:57, 1197.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5344927536231884\n",
      "Train loss: 0.03154577407985926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [4:57:21<00:00, 1189.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5489855072463768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting if we want to visualize training evolution per epochs after the training process\n",
    "train_loss_set = []\n",
    "loss_train = []\n",
    "accuracy_validation = []\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):  \n",
    "    # Tracking variables for training\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Get loss value\n",
    "        loss = outputs[0]\n",
    "        # Add it to train loss list\n",
    "        train_loss_set.append(loss.item())    \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "    loss_train.append(tr_loss/nb_tr_steps)\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "    # Tracking variables for validation\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Validation of the model\n",
    "    model.eval()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions\n",
    "            outputs =  model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss, logits = outputs[:2]\n",
    "    \n",
    "        # Move logits and labels to CPU if GPU is used\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "    \n",
    "    accuracy_validation.append(eval_accuracy/nb_eval_steps)\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_train, label = 'Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('Training_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_validation, label = 'Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('Validation_accuracy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_to_proba(x):\n",
    "\n",
    "    x = 1/(1+np.exp(-logits))\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i,:] = x[i,:]/np.sum(x[i,:])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.read_csv('Projet_Tweet_vaccin_fichier_3_pour_tester_la_fonction.csv', delimiter = \";\", \n",
    "                             encoding = 'latin_1')['text'].to_list()\n",
    "comments = tt[0:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the comments\n",
    "tokenized_comments_ids = [tokenizer.encode(comment,add_special_tokens=True,max_length=MAX_LEN) for comment in comments]\n",
    "# Pad the resulted encoded comments\n",
    "tokenized_comments_ids = pad_sequences(tokenized_comments_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks \n",
    "attention_masks = []\n",
    "for seq in tokenized_comments_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)\n",
    "\n",
    "prediction_inputs = torch.tensor(tokenized_comments_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the finetuned model (Camembert)\n",
    "flat_pred = []\n",
    "with torch.no_grad():\n",
    "    # Forward pass, calculate logit predictions\n",
    "    outputs =  model(prediction_inputs.to(device),token_type_ids=None, attention_mask=prediction_masks.to(device))\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy() \n",
    "    flat_pred.extend(np.argmax(logits, axis=1).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"tweet\": comments, \"classification\": flat_pred})\n",
    "df.to_csv(\"classification_label1.csv\",index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
