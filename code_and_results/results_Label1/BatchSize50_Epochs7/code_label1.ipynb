{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "# Choix du label \n",
    "\n",
    "#label = 'Label_2'\n",
    "#nombre_labels = 5\n",
    "\n",
    "label = 'Label_1'\n",
    "nombre_labels = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing standard libraries for every machine/deep learning pipeline\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Importing specific libraries for data prerpcessing, model archtecture choice, training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2cc8cb21190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# 5. Pytorch random number generator\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "epochs = 7\n",
    "MAX_LEN = 128\n",
    "batch_size = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df_training = pd.read_csv('Projet_Tweet_vaccin_fichier_1.1_labelises_pour_creer_la_fonction.csv', delimiter = \";\", encoding = 'latin_1')\n",
    "df_validation = pd.read_csv('Projet_Tweet_vaccin_fichier_1.2_labelises_pour_tester_la_fonction.csv', delimiter = \";\", encoding = 'latin_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_training, df_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CamemBERT tokenizer\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert/camembert-large',do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "# Creates list of texts and labels\n",
    "text = df['text'].to_list()\n",
    "labels = df[label].to_list()\n",
    "\n",
    "#user tokenizer to convert tokenizer = CamembertTokenizer.from_pretrained('camembert-base',do_lower_case=True)ces into tokenizer\n",
    "input_ids  = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN) for sent in text]\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]  \n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(input_ids, labels, attention_masks,\n",
    "                                                            random_state=42, test_size=0.1)\n",
    "\n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert/camembert-large were not used when initializing CamembertForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert/camembert-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CamembertForSequenceClassification, the pretrained camembert model with a single linear classification layer on top. \n",
    "model = CamembertForSequenceClassification.from_pretrained('camembert/camembert-large', num_labels = nombre_labels)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cdcha\\Anaconda3\\envs\\transformers8\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=10e-8)\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.337529186849241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  14%|█▍        | 1/7 [20:01<2:00:07, 1201.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.34927536231884054\n",
      "Train loss: 1.3111118872960408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  29%|██▊       | 2/7 [39:59<1:39:56, 1199.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3498550724637681\n",
      "Train loss: 1.2710235913594563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  43%|████▎     | 3/7 [59:56<1:19:53, 1198.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4515942028985507\n",
      "Train loss: 1.1205914285447862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  57%|█████▋    | 4/7 [1:19:50<59:50, 1196.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.40492753623188404\n",
      "Train loss: 1.0083588163057964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  71%|███████▏  | 5/7 [1:39:45<39:51, 1195.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.4721739130434783\n",
      "Train loss: 0.799042484274617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  86%|████████▌ | 6/7 [1:59:38<19:54, 1194.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.513913043478261\n",
      "Train loss: 0.607875923315684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 7/7 [2:19:30<00:00, 1195.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5423188405797101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting if we want to visualize training evolution per epochs after the training process\n",
    "train_loss_set = []\n",
    "loss_train = []\n",
    "accuracy_validation = []\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):  \n",
    "    # Tracking variables for training\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Get loss value\n",
    "        loss = outputs[0]\n",
    "        # Add it to train loss list\n",
    "        train_loss_set.append(loss.item())    \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "    loss_train.append(tr_loss/nb_tr_steps)\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "    # Tracking variables for validation\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Validation of the model\n",
    "    model.eval()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions\n",
    "            outputs =  model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss, logits = outputs[:2]\n",
    "    \n",
    "        # Move logits and labels to CPU if GPU is used\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "    \n",
    "    accuracy_validation.append(eval_accuracy/nb_eval_steps)\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_train, label = 'Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('Training_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_validation, label = 'Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('Validation_accuracy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_to_proba(x):\n",
    "\n",
    "    x = 1/(1+np.exp(-logits))\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i,:] = x[i,:]/np.sum(x[i,:])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.read_csv('Projet_Tweet_vaccin_fichier_3_pour_tester_la_fonction.csv', delimiter = \";\", \n",
    "                             encoding = 'latin_1')['text'].to_list()\n",
    "comments = tt[0:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the comments\n",
    "tokenized_comments_ids = [tokenizer.encode(comment,add_special_tokens=True,max_length=MAX_LEN) for comment in comments]\n",
    "# Pad the resulted encoded comments\n",
    "tokenized_comments_ids = pad_sequences(tokenized_comments_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks \n",
    "attention_masks = []\n",
    "for seq in tokenized_comments_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)\n",
    "\n",
    "prediction_inputs = torch.tensor(tokenized_comments_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the finetuned model (Camembert)\n",
    "flat_pred = []\n",
    "with torch.no_grad():\n",
    "    # Forward pass, calculate logit predictions\n",
    "    outputs =  model(prediction_inputs.to(device),token_type_ids=None, attention_mask=prediction_masks.to(device))\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy() \n",
    "    flat_pred.extend(np.argmax(logits, axis=1).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"tweet\": comments, \"classification\": flat_pred})\n",
    "df.to_csv(\"classification_label1.csv\",index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
