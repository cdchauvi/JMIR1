{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "# Choix du label \n",
    "\n",
    "label = 'Label_2'\n",
    "nombre_labels = 5\n",
    "\n",
    "#label = 'Label_1'\n",
    "#nombre_labels = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing standard libraries for every machine/deep learning pipeline\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Importing specific libraries for data prerpcessing, model archtecture choice, training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28c15bf2190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# 5. Pytorch random number generator\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "epochs = 20\n",
    "MAX_LEN = 128\n",
    "batch_size = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df_training = pd.read_csv('Projet_Tweet_vaccin_fichier_1.1_labelises_pour_creer_la_fonction.csv', delimiter = \";\", encoding = 'latin_1')\n",
    "df_validation = pd.read_csv('Projet_Tweet_vaccin_fichier_1.2_labelises_pour_tester_la_fonction.csv', delimiter = \";\", encoding = 'latin_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_training, df_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CamemBERT tokenizer\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert/camembert-large',do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "# Creates list of texts and labels\n",
    "text = df['text'].to_list()\n",
    "labels = df[label].to_list()\n",
    "\n",
    "#user tokenizer to convert tokenizer = CamembertTokenizer.from_pretrained('camembert-base',do_lower_case=True)ces into tokenizer\n",
    "input_ids  = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN) for sent in text]\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]  \n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(input_ids, labels, attention_masks,\n",
    "                                                            random_state=42, test_size=0.1)\n",
    "\n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert/camembert-large were not used when initializing CamembertForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert/camembert-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CamembertForSequenceClassification, the pretrained camembert model with a single linear classification layer on top. \n",
    "model = CamembertForSequenceClassification.from_pretrained('camembert/camembert-large', num_labels = nombre_labels)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cdcha\\Anaconda3\\envs\\transformers8\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=10e-8)\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.4489217047338132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   5%|▌         | 1/20 [20:06<6:22:11, 1206.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.595072463768116\n",
      "Train loss: 1.1067720232186493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 2/20 [40:12<6:01:55, 1206.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.518840579710145\n",
      "Train loss: 0.9275520576371087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  15%|█▌        | 3/20 [1:00:18<5:41:38, 1205.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6095652173913043\n",
      "Train loss: 0.633631357440242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 4/20 [1:20:24<5:21:36, 1206.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6034782608695651\n",
      "Train loss: 0.4729824866409655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|██▌       | 5/20 [1:40:30<5:01:31, 1206.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6246376811594203\n",
      "Train loss: 0.3275606566005283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|███       | 6/20 [2:00:36<4:41:22, 1205.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6713043478260868\n",
      "Train loss: 0.23530195239517424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  35%|███▌      | 7/20 [2:20:40<4:21:08, 1205.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6034782608695654\n",
      "Train loss: 0.12276189484530026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 8/20 [2:40:47<4:01:11, 1205.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5944927536231884\n",
      "Train loss: 0.08086363860854397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  45%|████▌     | 9/20 [3:00:53<3:41:05, 1205.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5884057971014492\n",
      "Train loss: 0.05935679210556878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 10/20 [3:21:00<3:21:03, 1206.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5944927536231884\n",
      "Train loss: 0.05140164767012552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  55%|█████▌    | 11/20 [3:41:04<3:00:50, 1205.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6107246376811595\n",
      "Train loss: 0.03562986084984408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 12/20 [4:00:59<2:40:19, 1202.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5678260869565218\n",
      "Train loss: 0.042186181164450116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  65%|██████▌   | 13/20 [4:20:50<2:19:52, 1198.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5901449275362319\n",
      "Train loss: 0.047684341255161494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|███████   | 14/20 [4:40:44<1:59:44, 1197.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6089855072463769\n",
      "Train loss: 0.025698676826087414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  75%|███████▌  | 15/20 [5:00:34<1:39:36, 1195.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6028985507246377\n",
      "Train loss: 0.02234993117895943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 16/20 [5:20:25<1:19:35, 1193.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5962318840579711\n",
      "Train loss: 0.05286362863801144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  85%|████████▌ | 17/20 [5:40:21<59:43, 1194.39s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.631304347826087\n",
      "Train loss: 0.023539138336976368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|█████████ | 18/20 [6:00:20<39:51, 1195.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6440579710144928\n",
      "Train loss: 0.0196700075606781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  95%|█████████▌| 19/20 [6:20:16<19:55, 1195.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6156521739130435\n",
      "Train loss: 0.0247382587166848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [6:40:10<00:00, 1200.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6434782608695652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting if we want to visualize training evolution per epochs after the training process\n",
    "train_loss_set = []\n",
    "loss_train = []\n",
    "accuracy_validation = []\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):  \n",
    "    # Tracking variables for training\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Get loss value\n",
    "        loss = outputs[0]\n",
    "        # Add it to train loss list\n",
    "        train_loss_set.append(loss.item())    \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "    loss_train.append(tr_loss/nb_tr_steps)\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "    # Tracking variables for validation\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Validation of the model\n",
    "    model.eval()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions\n",
    "            outputs =  model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss, logits = outputs[:2]\n",
    "    \n",
    "        # Move logits and labels to CPU if GPU is used\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "    \n",
    "    accuracy_validation.append(eval_accuracy/nb_eval_steps)\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_train, label = 'Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('Training_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_validation, label = 'Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('Validation_accuracy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_to_proba(x):\n",
    "\n",
    "    x = 1/(1+np.exp(-logits))\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i,:] = x[i,:]/np.sum(x[i,:])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.read_csv('Projet_Tweet_vaccin_fichier_3_pour_tester_la_fonction.csv', delimiter = \";\", \n",
    "                             encoding = 'latin_1')['text'].to_list()\n",
    "comments = tt[0:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the comments\n",
    "tokenized_comments_ids = [tokenizer.encode(comment,add_special_tokens=True,max_length=MAX_LEN) for comment in comments]\n",
    "# Pad the resulted encoded comments\n",
    "tokenized_comments_ids = pad_sequences(tokenized_comments_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks \n",
    "attention_masks = []\n",
    "for seq in tokenized_comments_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)\n",
    "\n",
    "prediction_inputs = torch.tensor(tokenized_comments_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the finetuned model (Camembert)\n",
    "flat_pred = []\n",
    "with torch.no_grad():\n",
    "    # Forward pass, calculate logit predictions\n",
    "    outputs =  model(prediction_inputs.to(device),token_type_ids=None, attention_mask=prediction_masks.to(device))\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy() \n",
    "    flat_pred.extend(np.argmax(logits, axis=1).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"tweet\": comments, \"classification\": flat_pred})\n",
    "df.to_csv(\"classification_label2.csv\",index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
