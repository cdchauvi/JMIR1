{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "# Choix du label \n",
    "\n",
    "label = 'Label_2'\n",
    "nombre_labels = 5\n",
    "\n",
    "#label = 'Label_1'\n",
    "#nombre_labels = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing standard libraries for every machine/deep learning pipeline\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Importing specific libraries for data prerpcessing, model archtecture choice, training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x202035d2d50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# 5. Pytorch random number generator\n",
    "torch.manual_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants\n",
    "epochs = 15\n",
    "MAX_LEN = 128\n",
    "batch_size = 50\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "df_training = pd.read_csv('Projet_Tweet_vaccin_fichier_1.1_labelises_pour_creer_la_fonction.csv', delimiter = \";\", encoding = 'latin_1')\n",
    "df_validation = pd.read_csv('Projet_Tweet_vaccin_fichier_1.2_labelises_pour_tester_la_fonction.csv', delimiter = \";\", encoding = 'latin_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_training, df_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CamemBERT tokenizer\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert/camembert-large',do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "# Creates list of texts and labels\n",
    "text = df['text'].to_list()\n",
    "labels = df[label].to_list()\n",
    "\n",
    "#user tokenizer to convert tokenizer = CamembertTokenizer.from_pretrained('camembert-base',do_lower_case=True)ces into tokenizer\n",
    "input_ids  = [tokenizer.encode(sent,add_special_tokens=True,max_length=MAX_LEN) for sent in text]\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]  \n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(input_ids, labels, attention_masks,\n",
    "                                                            random_state=42, test_size=0.1)\n",
    "\n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert/camembert-large were not used when initializing CamembertForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert/camembert-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CamembertForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32005, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CamembertForSequenceClassification, the pretrained camembert model with a single linear classification layer on top. \n",
    "model = CamembertForSequenceClassification.from_pretrained('camembert/camembert-large', num_labels = nombre_labels)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps=10e-8)\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.4489217047338132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|▋         | 1/15 [38:23<8:57:31, 2303.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.595072463768116\n",
      "Train loss: 1.1067720232186493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|█▎        | 2/15 [1:14:55<8:04:55, 2238.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.518840579710145\n",
      "Train loss: 0.9275520576371087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 3/15 [1:51:47<7:25:12, 2226.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6095652173913043\n",
      "Train loss: 0.633631357440242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|██▋       | 4/15 [2:29:21<6:50:08, 2237.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6034782608695651\n",
      "Train loss: 0.4729824866409655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|███▎      | 5/15 [3:07:06<6:14:30, 2247.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6246376811594203\n",
      "Train loss: 0.3275606566005283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 6/15 [3:43:51<5:34:56, 2232.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6713043478260868\n",
      "Train loss: 0.23530195239517424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|████▋     | 7/15 [4:20:56<4:57:22, 2230.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6034782608695654\n",
      "Train loss: 0.12276189484530026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|█████▎    | 8/15 [4:58:24<4:20:51, 2235.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5944927536231884\n",
      "Train loss: 0.08086363860854397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 9/15 [5:35:10<3:42:38, 2226.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5884057971014492\n",
      "Train loss: 0.05935679210556878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████▋   | 10/15 [6:12:51<3:06:25, 2237.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5944927536231884\n",
      "Train loss: 0.05140164767012552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|███████▎  | 11/15 [6:51:23<2:30:40, 2260.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6107246376811595\n",
      "Train loss: 0.03562986084984408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 12/15 [7:28:55<1:52:52, 2257.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5678260869565218\n",
      "Train loss: 0.042186181164450116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|████████▋ | 13/15 [8:05:57<1:14:53, 2246.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5901449275362319\n",
      "Train loss: 0.047684341255161494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|█████████▎| 14/15 [8:44:19<37:43, 2263.64s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6089855072463769\n",
      "Train loss: 0.025698676826087414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 15/15 [9:21:55<00:00, 2247.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6028985507246377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Store our loss and accuracy for plotting if we want to visualize training evolution per epochs after the training process\n",
    "train_loss_set = []\n",
    "loss_train = []\n",
    "accuracy_validation = []\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(epochs, desc=\"Epoch\"):  \n",
    "    # Tracking variables for training\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Clear out the gradients (by default they accumulate)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        # Get loss value\n",
    "        loss = outputs[0]\n",
    "        # Add it to train loss list\n",
    "        train_loss_set.append(loss.item())    \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Update tracking variables\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "    loss_train.append(tr_loss/nb_tr_steps)\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "    # Tracking variables for validation\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    # Validation of the model\n",
    "    model.eval()\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        # Add batch to device CPU or GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions\n",
    "            outputs =  model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss, logits = outputs[:2]\n",
    "    \n",
    "        # Move logits and labels to CPU if GPU is used\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "    \n",
    "    accuracy_validation.append(eval_accuracy/nb_eval_steps)\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_train, label = 'Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('Training_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_validation, label = 'Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('Validation_accuracy.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_to_proba(x):\n",
    "\n",
    "    x = 1/(1+np.exp(-logits))\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i,:] = x[i,:]/np.sum(x[i,:])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.read_csv('Projet_Tweet_vaccin_fichier_3_pour_tester_la_fonction.csv', delimiter = \";\", \n",
    "                             encoding = 'latin_1')['text'].to_list()\n",
    "comments = tt[0:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the comments\n",
    "tokenized_comments_ids = [tokenizer.encode(comment,add_special_tokens=True,max_length=MAX_LEN) for comment in comments]\n",
    "# Pad the resulted encoded comments\n",
    "tokenized_comments_ids = pad_sequences(tokenized_comments_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks \n",
    "attention_masks = []\n",
    "for seq in tokenized_comments_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)\n",
    "\n",
    "prediction_inputs = torch.tensor(tokenized_comments_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the finetuned model (Camembert)\n",
    "flat_pred = []\n",
    "with torch.no_grad():\n",
    "    # Forward pass, calculate logit predictions\n",
    "    outputs =  model(prediction_inputs.to(device),token_type_ids=None, attention_mask=prediction_masks.to(device))\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy() \n",
    "    flat_pred.extend(np.argmax(logits, axis=1).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"tweet\": comments, \"classification\": flat_pred})\n",
    "df.to_csv(\"classification_label2.csv\",index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
